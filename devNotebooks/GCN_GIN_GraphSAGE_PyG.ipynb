{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GraphSAGE, GCN, GIN\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VnAeTzIwjSZ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPrGcTX8c7E-",
        "outputId": "c635dd1e-1328-4d8f-d87e-ff44db5eaa00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyH3teNzaWd6",
        "outputId": "23641701-a5d1-4b87-ba73-d3cd2e127d47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
        "!pip install torch-geometric\n",
        "!pip install ogb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aslrYOMqorss",
        "outputId": "c4c9fb71-3c64-42f4-e301-7d9c2c84b087"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.11.0+cu113 in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision==0.12.0+cu113 in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0+cu113) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0+cu113) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0+cu113) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision==0.12.0+cu113) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==0.12.0+cu113) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 2.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.13\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=078330b2b0a8db00d3667b5313118d4cd71ac3f7c8e7e34ca857727a4e0f45a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ogb\n",
            "  Downloading ogb-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting outdated>=0.2.0\n",
            "  Downloading outdated-0.2.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.24.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.0.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (4.64.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.3.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.11.0+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (2.23.0)\n",
            "Collecting littleutils\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb) (4.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=dde2fc7608901c86ccc5a841f9154a48ce7147712591ff7d617b647b0008e55f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/64/cd/32819b511a488e4993f2fab909a95330289c3f4e0f6ef4676d\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.3 outdated-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uNqsi6VWAlWo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/data/aesthetics') \n",
        "\n",
        "import os.path as osp\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "from data import get_data, get_data_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"\"\n",
        "data = get_data(path)\n",
        "data.edge_index=data.edge_index.long()\n",
        "train_data, val_data, test_data = get_data_split(path)\n",
        "train_data.edge_index=train_data.edge_index.long()\n",
        "val_data.edge_index=val_data.edge_index.long()\n",
        "test_data.edge_index=test_data.edge_index.long()\n",
        "data = train_test_split_edges(data)"
      ],
      "metadata": {
        "id": "wcfiqGUx1Upz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "795ddb2d-07d2-45a3-e27c-4e6be765f3fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dota = get_data(path)\n",
        "dota.edge_index=dota.edge_index.long()\n",
        "dota.edge_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j1gg05_iErT",
        "outputId": "da77a7fd-5a81-4342-e158-f8b11fc7fc60"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11, 11,  8, 16, 17,  5, 13, 42, 29,  4,  5,  8,  0, 13, 14, 21,  2, 28,\n",
              "         12, 25, 14, 34, 11, 13, 14, 16, 29, 21, 11, 20, 16, 25,  4, 11,  4, 15,\n",
              "         11, 10, 20, 13,  4,  7, 35, 17,  5, 13, 17, 18, 29, 16, 20, 31, 24, 11,\n",
              "          4, 14, 10,  0,  6, 11, 22, 22, 11,  5, 15,  8,  2,  8, 34, 15,  4,  6,\n",
              "         17,  5, 14, 17,  2, 29, 17,  8, 24, 16, 25, 13, 37,  8, 20, 28, 23, 41,\n",
              "          4, 15, 21,  2, 12,  4, 39, 23, 31, 37, 11, 17,  6, 14, 39, 35, 36, 16,\n",
              "         20, 20, 11,  5, 24,  2, 13, 12,  5, 11, 31, 25,  4,  5, 23, 20,  1,  4,\n",
              "         36,  6,  7, 38, 23, 16, 41, 17, 21, 20, 25, 16, 14, 16, 15, 15, 24,  1,\n",
              "         20,  2,  6, 14,  2, 34,  4, 24, 28, 23, 31, 31, 17, 15, 39,  7,  7, 28,\n",
              "         14, 23,  8,  5, 23, 10, 22, 25, 11, 21, 36,  4, 15,  4, 22],\n",
              "        [15, 20, 13, 18, 23, 13, 32, 43, 38, 17, 27, 29,  2, 35, 22, 28, 31, 33,\n",
              "         23, 35, 20, 36, 14, 31, 15, 25, 37, 24, 23, 34, 42, 41, 23, 29, 31, 22,\n",
              "         18, 27, 29, 20, 37, 27, 39, 40,  6, 37, 34, 28, 32, 39, 32, 34, 34, 37,\n",
              "         21, 37, 12, 37,  8, 21, 41, 43, 28, 32, 18, 12, 14, 31, 40, 42,  5, 27,\n",
              "         37, 10, 35, 24,  4, 34, 31, 28, 38, 35, 39, 28, 38, 24, 36, 37, 24, 43,\n",
              "         34, 39, 29, 20, 13, 11, 43, 37, 37, 40, 24, 38,  7, 25, 42, 43, 37, 41,\n",
              "         23, 31, 31, 29, 40, 17, 18, 24,  7, 35, 32, 28, 20, 17, 31, 37, 28, 13,\n",
              "         40, 10, 10, 40, 29, 28, 42, 20, 25, 21, 42, 22, 42, 43, 25, 35, 29, 22,\n",
              "         28, 37, 32, 16,  3, 37, 32, 37, 42, 40, 38, 40, 29, 28, 41, 20, 33, 39,\n",
              "         28, 32, 32, 12, 34, 32, 25, 37, 32, 32, 38, 29, 21, 40, 42]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# If you use GPU, the device should be cuda\n",
        "print('Device: {}'.format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSAtZPLMem2A",
        "outputId": "410d4f7e-b8f1-4c98-d7b6-09f26658ed87"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "----\n",
        "\n",
        "# Other kind\n",
        "\n",
        "----\n",
        "---"
      ],
      "metadata": {
        "id": "9Db4qN7AyeXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU\n",
        "\n",
        "from torch_geometric.utils import negative_sampling, to_dense_adj, dense_to_sparse\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GINConv, GATConv\n",
        "\n",
        "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_sparse import SparseTensor\n",
        "from torch_geometric.nn import Node2Vec\n",
        "\n",
        "import pandas as pd\n",
        "import shutil, os\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "\n",
        "#from logger import Logger\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "JwSUzzlxnTiH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGE(torch.nn.Module):\n",
        "  ''' Define GCN network. '''\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
        "                 dropout):\n",
        "        super(SAGE, self).__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
        "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "  def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "  def forward(self, x, adj_t):\n",
        "      # Execute conv -> relu -> dropout sequence\n",
        "        for conv in self.convs[:-1]:\n",
        "            x = conv(x, adj_t)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.convs[-1](x, adj_t)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "  ''' Define GCN network. '''\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
        "                 dropout):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(\n",
        "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
        "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "  def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "  def forward(self, x, adj_t):\n",
        "        # Execute conv -> relu -> dropout sequence\n",
        "        for conv in self.convs[:-1]:\n",
        "            x = conv(x, adj_t)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.convs[-1](x, adj_t)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GIN(torch.nn.Module):\n",
        "  ''' Define graph isomorphic network. '''\n",
        "  def __init__(self, in_channels, dim, out_channels, num_layers,dropout):\n",
        "        super().__init__()\n",
        "         # # Initialize 2 GINConv layers (following num_layers=2 in model-agnostic hyperparams as specified in the blogpost)\n",
        "        self.conv1 = GINConv(\n",
        "            Sequential(Linear(in_channels, dim), BatchNorm1d(dim), ReLU(),\n",
        "                       Linear(dim, dim), ReLU())) # GINConv takes a neural network as input\n",
        "\n",
        "        self.conv2 = GINConv(\n",
        "            Sequential(Linear(dim, dim), BatchNorm1d(dim), ReLU(),\n",
        "                       Linear(dim, dim), ReLU()))\n",
        "        \n",
        "        self.dropout = dropout\n",
        "  \n",
        "  def reset_parameters(self):\n",
        "        self.conv1.reset_parameters()\n",
        "        self.conv2.reset_parameters()\n",
        "\n",
        "  def forward(self, x, adj_t):\n",
        "       # Execute conv -> relu -> dropout sequence\n",
        "        x = self.conv1(x, adj_t)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, adj_t)\n",
        "        return x\n",
        "\n",
        "# class in order to predict whether a link exists between two nodes using \n",
        "# their embeddings, x_i and x_j\n",
        "class LinkPredictor(torch.nn.Module):\n",
        "    ''' Neural network which predicts whether a link (interaction) exists between 2 nodes i,j \n",
        "    given their embeddings x_i, x_j. \n",
        "    '''\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
        "                 dropout):\n",
        "        super(LinkPredictor, self).__init__()\n",
        "\n",
        "        self.lins = torch.nn.ModuleList()\n",
        "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
        "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for lin in self.lins:\n",
        "            lin.reset_parameters()\n",
        "\n",
        "    def forward(self, x_i, x_j):\n",
        "        x = x_i * x_j # hadamard product\n",
        "        for lin in self.lins[:-1]: # linear layer -> relu -> dropout\n",
        "            x = lin(x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.lins[-1](x)\n",
        "        return torch.sigmoid(x) # sigmoid activation outputs probability that a given edge exists for all node pairs\n",
        "\n",
        "class DotProductLinkPredictor(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DotProductLinkPredictor, self).__init__()\n",
        "\n",
        "    def forward(self, x_i, x_j):\n",
        "        out = (x_i*x_j).sum(-1)\n",
        "        return torch.sigmoid(out)\n",
        "    \n",
        "    def reset_parameters(self):\n",
        "      pass"
      ],
      "metadata": {
        "id": "pRyH06_QVTwT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_args = { # define GNN hyperparams\n",
        "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "    'hidden_size': 25,\n",
        "    'input_size': data.x.shape[1],\n",
        "    'dropout': 0.5,\n",
        "    'epochs': 100,\n",
        "    'weight_decay': 1e-5,\n",
        "    'lr': 0.005,\n",
        "    'attn_size': 32,\n",
        "    'num_layers':2,\n",
        "    'log_steps':100,\n",
        "    'eval_steps':5,\n",
        "    'runs':10,\n",
        "    'batch_size': 64*1024,\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "dbBIybjxlL_D"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj_t = SparseTensor(row=dota.edge_index[0], col=dota.edge_index[1],\n",
        "                   sparse_sizes=(data.num_nodes, data.num_nodes))"
      ],
      "metadata": {
        "id": "fRdn6Z8CkGYv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, predictor, adj_t, data, optimizer, batch_size):\n",
        "\n",
        "    embedding= torch.nn.Embedding(data.x.shape[0],data.x.shape[1]).to(device)\n",
        "\n",
        "    embedding.weight.data.copy_(data.x)\n",
        "    x=embedding.weight\n",
        "\n",
        "    row, col = data.train_pos_edge_index\n",
        "    edge_index = torch.stack([col, row], dim=0) # data.train_pos_edge_index mit vertauschten Elementen\n",
        "\n",
        "    model.train()\n",
        "    predictor.train()\n",
        "\n",
        "    pos_train_edge = data.train_pos_edge_index.T.to(x.device) # [node1, node 1a],....\n",
        "\n",
        "    total_loss = total_examples = 0\n",
        "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size,\n",
        "                           shuffle=True):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        h = model(x, adj_t)\n",
        "\n",
        "        edge = pos_train_edge[perm].t()\n",
        "\n",
        "        # computes the loss for positive edges\n",
        "        pos_out = predictor(h[edge[0]], h[edge[1]])\n",
        "        pos_loss = -torch.log(pos_out + 1e-15).mean()\n",
        "\n",
        "        # samples negative edges from the graph\n",
        "        edge = negative_sampling(edge_index, num_nodes=x.size(0),\n",
        "                                 num_neg_samples=perm.size(0), method='dense')\n",
        "\n",
        "        # computes the loss for negative edges\n",
        "        neg_out = predictor(h[edge[0]], h[edge[1]])\n",
        "        neg_loss = -torch.log(1 - neg_out + 1e-15).mean()\n",
        "\n",
        "        loss = pos_loss + neg_loss\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(x, 1.0)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        num_examples = pos_out.size(0)\n",
        "        total_loss += loss.item() * num_examples\n",
        "        total_examples += num_examples\n",
        "\n",
        "    return total_loss / total_examples\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, predictor, adj_t, data,  batch_size):\n",
        "    model.eval()\n",
        "    predictor.eval()\n",
        "\n",
        "    embedding= torch.nn.Embedding(data.x.shape[0],data.x.shape[1]).to(device)\n",
        "\n",
        "    embedding.weight.data.copy_(data.x) \n",
        "    x=embedding.weight\n",
        "\n",
        "    h = model(x, adj_t)\n",
        "    \n",
        "    pos_train_edge = data.train_pos_edge_index.T.to(x.device)\n",
        "    pos_valid_edge = data.val_pos_edge_index.T.to(x.device)\n",
        "    neg_valid_edge = data.val_neg_edge_index.T.to(x.device)\n",
        "    pos_test_edge = data.test_pos_edge_index.T.to(x.device)\n",
        "    neg_test_edge = data.test_neg_edge_index.T.to(x.device)\n",
        "\n",
        "    # store what the link predictor outputs for each positive and negative \n",
        "    # edge in order to compute the hits@K\n",
        "    pos_train_preds = []\n",
        "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size):\n",
        "        edge = pos_train_edge[perm].t()\n",
        "        pos_train_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    pos_train_pred = torch.cat(pos_train_preds, dim=0)\n",
        "\n",
        "    pos_valid_preds = []\n",
        "    for perm in DataLoader(range(pos_valid_edge.size(0)), batch_size):\n",
        "        edge = pos_valid_edge[perm].t()\n",
        "        pos_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
        "\n",
        "    neg_valid_preds = []\n",
        "    for perm in DataLoader(range(neg_valid_edge.size(0)), batch_size):\n",
        "        edge = neg_valid_edge[perm].t()\n",
        "        neg_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
        "\n",
        "    pos_test_preds = []\n",
        "    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n",
        "        edge = pos_test_edge[perm].t()\n",
        "        pos_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
        "\n",
        "    neg_test_preds = []\n",
        "    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n",
        "        edge = neg_test_edge[perm].t()\n",
        "        neg_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
        "\n",
        "    # compute the hits@K for training, validation, and test\n",
        "\n",
        "    def compute_loss(pos_score, neg_score):  # computes the loss based on binary cross entropy\n",
        "        scores = torch.cat([pos_score, neg_score])\n",
        "        labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
        "        return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "    def compute_auc(pos_score, neg_score):  # computes AUC (Area-Under-Curve) score\n",
        "        scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "        labels = torch.cat(\n",
        "            [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
        "        return roc_auc_score(labels, scores)\n",
        "    results = {}\n",
        "    train_hits=compute_auc(pos_train_pred, neg_test_pred)\n",
        "    test_hits=compute_auc(pos_test_pred, neg_test_pred)\n",
        "    valid_hits=compute_auc(pos_valid_pred, neg_valid_pred)\n",
        "    results[f'Hm'] = (train_hits, valid_hits, test_hits)\n",
        "\n",
        "  \n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "V7IkepM_niOi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, data, gnn_args, predictor, model_name): \n",
        "  ''' \n",
        "  Train specified GNN model. Model and embeddings should be initialized. \n",
        "  Save model after every run. \n",
        "  '''\n",
        "  train_hits_arr, val_hits_arr, test_hits_arr = [], [], []\n",
        "  \n",
        "  embedding= torch.nn.Embedding(data.x.shape[0],data.x.shape[1]).to(device)\n",
        "\n",
        "  embedding.weight.data.copy_(data.x) \n",
        "\n",
        "  emb=embedding\n",
        "\n",
        "  split_edge=dota.edge_index.T\n",
        "\n",
        "  \n",
        "  for run in range(20):\n",
        "    max_valhits, train_hits_run, test_hits_run = float('-inf'), 0, 0\n",
        "    \n",
        "    \n",
        "    model.reset_parameters()\n",
        "    predictor.reset_parameters()\n",
        "    optimizer = torch.optim.Adam(\n",
        "        list(model.parameters()) + list(emb.parameters()) +\n",
        "        list(predictor.parameters()), lr=gnn_args['lr'])\n",
        "\n",
        "    for epoch in range(1, 1 + gnn_args['epochs']):\n",
        "        loss = train(model, predictor,  adj_t, data,optimizer, gnn_args['batch_size'])\n",
        "        if epoch % gnn_args['eval_steps'] == 0:\n",
        "            results = test(model, predictor, adj_t, data, gnn_args['batch_size'])\n",
        "            \n",
        "\n",
        "            if epoch % gnn_args['log_steps'] == 0:\n",
        "                for key, result in results.items():\n",
        "                    train_hits, valid_hits, test_hits = result\n",
        "                    print(key)\n",
        "                    print(f'Run: {run + 1:02d}, '\n",
        "                          f'Epoch: {epoch:02d}, '\n",
        "                          f'Loss: {loss:.4f}, '\n",
        "                          f'Train: {100 * train_hits:.2f}%, '\n",
        "                          f'Valid: {100 * valid_hits:.2f}%, '\n",
        "                          f'Test: {100 * test_hits:.2f}%')\n",
        "                print('---')\n",
        "    \n",
        "            # check val-hits@20\n",
        "            train_hits, valid_hits, test_hits = results['Hm']\n",
        "            if valid_hits >= max_valhits: # if validhits20 is higher than max, save ckpt               \n",
        "              max_valhits = valid_hits\n",
        "              train_hits_run = train_hits\n",
        "              test_hits_run = test_hits\n",
        "              # Save model checkpoint for current run.\n",
        "              model_path = f\"training_outputs/{model_name}.pt\"\n",
        "              emb_path = f'training_outputs/{model_name}_init_emb.pt'\n",
        "              #save_model_ckpt(model, emb, optimizer, predictor, loss, emb_path, model_path)\n",
        "    train_hits_arr.append(train_hits_run)\n",
        "    test_hits_arr.append(test_hits_run)\n",
        "    val_hits_arr.append(max_valhits)\n",
        "\n",
        "\n",
        "  # Print overall stats arrays for best model based on val hits@20\n",
        "  print(\"Val_roc: \", val_hits_arr)\n",
        "  print(\"Test_roc: \", test_hits_arr)\n",
        "  print(\"Train_roc: \", train_hits_arr)\n",
        "\n",
        "  # Print best model stats (based on val hits@20)\n",
        "  val_max = max(val_hits_arr)\n",
        "  print(\"Best model val: \", max(val_hits_arr))\n",
        "  max_idx = val_hits_arr.index(val_max)\n",
        "  print('Best model test: ', test_hits_arr[max_idx])\n",
        "  print('Best model train: ', val_hits_arr[max_idx])\n",
        "\n",
        "  # convert to numpy array\n",
        "  val_hits_arr = np.array(val_hits_arr)\n",
        "  test_hits_arr = np.array(test_hits_arr)\n",
        "  train_hits_arr = np.array(train_hits_arr)\n",
        "\n",
        "  # Print average stats + variance\n",
        "  print(f\"Average best train: {np.mean(train_hits_arr)}; var: {np.var(train_hits_arr)}\")\n",
        "  print(f\"Average best val: {np.mean(val_hits_arr)}; var: {np.var(val_hits_arr)}\")\n",
        "  print(f\"Average best test: {np.mean(test_hits_arr)}; var: {np.var(test_hits_arr)}\")"
      ],
      "metadata": {
        "id": "vGjKLsiqsKHY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "model_name = 'sage'\n",
        "sage_model = SAGE(gnn_args['input_size'], gnn_args['hidden_size'], gnn_args['hidden_size'], \n",
        "              gnn_args['num_layers'], gnn_args['dropout']).to(device)  \n",
        "predictor = LinkPredictor(gnn_args['hidden_size'], gnn_args['hidden_size'], 1,\n",
        "                          gnn_args['num_layers'], gnn_args['dropout']).to(device)\n",
        "\n",
        "train_model(sage_model, data, gnn_args, predictor, 'sage')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK2FVozHlRxV",
        "outputId": "c7a4c423-e277-4fcd-b2af-9d7f9c088656"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hm\n",
            "Run: 01, Epoch: 100, Loss: 0.8700, Train: 92.61%, Valid: 96.88%, Test: 87.20%\n",
            "---\n",
            "Hm\n",
            "Run: 02, Epoch: 100, Loss: 1.0911, Train: 88.39%, Valid: 89.06%, Test: 88.93%\n",
            "---\n",
            "Hm\n",
            "Run: 03, Epoch: 100, Loss: 0.8419, Train: 96.01%, Valid: 92.19%, Test: 92.39%\n",
            "---\n",
            "Hm\n",
            "Run: 04, Epoch: 100, Loss: 0.8745, Train: 91.25%, Valid: 89.06%, Test: 87.89%\n",
            "---\n",
            "Hm\n",
            "Run: 05, Epoch: 100, Loss: 0.8381, Train: 91.83%, Valid: 89.06%, Test: 89.27%\n",
            "---\n",
            "Hm\n",
            "Run: 06, Epoch: 100, Loss: 0.7787, Train: 95.78%, Valid: 93.75%, Test: 93.08%\n",
            "---\n",
            "Hm\n",
            "Run: 07, Epoch: 100, Loss: 0.8194, Train: 91.29%, Valid: 93.75%, Test: 88.24%\n",
            "---\n",
            "Hm\n",
            "Run: 08, Epoch: 100, Loss: 0.8266, Train: 89.51%, Valid: 89.06%, Test: 86.85%\n",
            "---\n",
            "Hm\n",
            "Run: 09, Epoch: 100, Loss: 0.8208, Train: 96.98%, Valid: 93.75%, Test: 93.77%\n",
            "---\n",
            "Hm\n",
            "Run: 10, Epoch: 100, Loss: 0.9636, Train: 95.70%, Valid: 90.62%, Test: 94.81%\n",
            "---\n",
            "Hm\n",
            "Run: 11, Epoch: 100, Loss: 0.6547, Train: 94.93%, Valid: 87.50%, Test: 92.04%\n",
            "---\n",
            "Hm\n",
            "Run: 12, Epoch: 100, Loss: 0.9598, Train: 93.27%, Valid: 93.75%, Test: 91.35%\n",
            "---\n",
            "Hm\n",
            "Run: 13, Epoch: 100, Loss: 0.8564, Train: 93.34%, Valid: 89.06%, Test: 89.97%\n",
            "---\n",
            "Hm\n",
            "Run: 14, Epoch: 100, Loss: 0.8708, Train: 96.40%, Valid: 92.19%, Test: 94.12%\n",
            "---\n",
            "Hm\n",
            "Run: 15, Epoch: 100, Loss: 0.8381, Train: 93.23%, Valid: 93.75%, Test: 88.58%\n",
            "---\n",
            "Hm\n",
            "Run: 16, Epoch: 100, Loss: 0.8407, Train: 92.72%, Valid: 89.06%, Test: 89.27%\n",
            "---\n",
            "Hm\n",
            "Run: 17, Epoch: 100, Loss: 0.9955, Train: 91.02%, Valid: 92.19%, Test: 86.51%\n",
            "---\n",
            "Hm\n",
            "Run: 18, Epoch: 100, Loss: 0.8536, Train: 94.78%, Valid: 89.06%, Test: 91.70%\n",
            "---\n",
            "Hm\n",
            "Run: 19, Epoch: 100, Loss: 0.8803, Train: 90.09%, Valid: 89.06%, Test: 87.20%\n",
            "---\n",
            "Hm\n",
            "Run: 20, Epoch: 100, Loss: 0.8317, Train: 94.04%, Valid: 90.62%, Test: 89.97%\n",
            "---\n",
            "Val_roc:  [0.96875, 0.890625, 0.9375, 0.96875, 0.90625, 0.9375, 0.9375, 0.9375, 0.96875, 0.96875, 0.9375, 0.953125, 0.96875, 0.9375, 0.9375, 0.921875, 0.953125, 0.9375, 0.9375, 0.90625]\n",
            "Test_roc:  [0.8719723183391003, 0.8892733564013842, 0.9273356401384083, 0.889273356401384, 0.8719723183391003, 0.9307958477508651, 0.8823529411764706, 0.8546712802768166, 0.8961937716262977, 0.9515570934256056, 0.944636678200692, 0.8788927335640139, 0.8166089965397925, 0.9480968858131489, 0.8858131487889273, 0.889273356401384, 0.8304498269896193, 0.9134948096885813, 0.7785467128027681, 0.8996539792387542]\n",
            "Train_roc:  [0.9260835913312693, 0.8839009287925697, 0.9551083591331269, 0.9229876160990711, 0.8885448916408668, 0.9578173374613003, 0.9129256965944272, 0.8808049535603715, 0.93343653250774, 0.9705882352941176, 0.9798761609907121, 0.8719040247678018, 0.8134674922600619, 0.9713622291021671, 0.9322755417956656, 0.8958978328173375, 0.8575851393188855, 0.9361455108359134, 0.8312693498452013, 0.9404024767801857]\n",
            "Best model val:  0.96875\n",
            "Best model test:  0.8719723183391003\n",
            "Best model train:  0.96875\n",
            "Average best train: 0.9131191950464395; var: 0.0020721632408055276\n",
            "Average best val: 0.940625; var: 0.0004785156249999999\n",
            "Average best test: 0.8875432525951558; var: 0.0018612085583266497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'gcn'\n",
        "\n",
        "predictor = LinkPredictor(gnn_args['hidden_size'], gnn_args['hidden_size'], 1,\n",
        "                          gnn_args['num_layers'], gnn_args['dropout']).to(device)\n",
        "\n",
        "gcn_model = GCN(gnn_args['input_size'], gnn_args['hidden_size'], gnn_args['hidden_size'], \n",
        "             gnn_args['num_layers'], gnn_args['dropout']).to(device)\n",
        "\n",
        "train_model(gcn_model, data, gnn_args, predictor, 'gcn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKWe8Um1E_sR",
        "outputId": "b4950084-bd59-4bcf-fa41-c45360cdad79"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hm\n",
            "Run: 01, Epoch: 100, Loss: 0.7996, Train: 90.91%, Valid: 85.94%, Test: 89.27%\n",
            "---\n",
            "Hm\n",
            "Run: 02, Epoch: 100, Loss: 0.8697, Train: 87.85%, Valid: 84.38%, Test: 87.89%\n",
            "---\n",
            "Hm\n",
            "Run: 03, Epoch: 100, Loss: 0.8448, Train: 93.54%, Valid: 87.50%, Test: 96.19%\n",
            "---\n",
            "Hm\n",
            "Run: 04, Epoch: 100, Loss: 0.8732, Train: 92.69%, Valid: 89.06%, Test: 93.08%\n",
            "---\n",
            "Hm\n",
            "Run: 05, Epoch: 100, Loss: 0.8160, Train: 91.68%, Valid: 89.06%, Test: 94.46%\n",
            "---\n",
            "Hm\n",
            "Run: 06, Epoch: 100, Loss: 0.8430, Train: 91.37%, Valid: 85.94%, Test: 92.73%\n",
            "---\n",
            "Hm\n",
            "Run: 07, Epoch: 100, Loss: 0.9096, Train: 95.59%, Valid: 90.62%, Test: 97.23%\n",
            "---\n",
            "Hm\n",
            "Run: 08, Epoch: 100, Loss: 1.0162, Train: 92.65%, Valid: 87.50%, Test: 92.73%\n",
            "---\n",
            "Hm\n",
            "Run: 09, Epoch: 100, Loss: 0.9320, Train: 92.03%, Valid: 84.38%, Test: 94.12%\n",
            "---\n",
            "Hm\n",
            "Run: 10, Epoch: 100, Loss: 0.9591, Train: 90.60%, Valid: 90.62%, Test: 93.43%\n",
            "---\n",
            "Hm\n",
            "Run: 11, Epoch: 100, Loss: 0.9435, Train: 90.63%, Valid: 84.38%, Test: 92.39%\n",
            "---\n",
            "Hm\n",
            "Run: 12, Epoch: 100, Loss: 0.9445, Train: 90.79%, Valid: 87.50%, Test: 90.66%\n",
            "---\n",
            "Hm\n",
            "Run: 13, Epoch: 100, Loss: 0.8921, Train: 90.52%, Valid: 90.62%, Test: 90.31%\n",
            "---\n",
            "Hm\n",
            "Run: 14, Epoch: 100, Loss: 0.9385, Train: 89.13%, Valid: 82.81%, Test: 89.27%\n",
            "---\n",
            "Hm\n",
            "Run: 15, Epoch: 100, Loss: 0.9000, Train: 92.96%, Valid: 85.94%, Test: 94.81%\n",
            "---\n",
            "Hm\n",
            "Run: 16, Epoch: 100, Loss: 0.8723, Train: 93.11%, Valid: 85.94%, Test: 94.12%\n",
            "---\n",
            "Hm\n",
            "Run: 17, Epoch: 100, Loss: 0.9838, Train: 91.49%, Valid: 87.50%, Test: 93.77%\n",
            "---\n",
            "Hm\n",
            "Run: 18, Epoch: 100, Loss: 1.0149, Train: 86.88%, Valid: 81.25%, Test: 88.24%\n",
            "---\n",
            "Hm\n",
            "Run: 19, Epoch: 100, Loss: 0.9251, Train: 92.69%, Valid: 87.50%, Test: 94.46%\n",
            "---\n",
            "Hm\n",
            "Run: 20, Epoch: 100, Loss: 1.0638, Train: 86.11%, Valid: 82.81%, Test: 89.27%\n",
            "---\n",
            "Val_roc:  [0.96875, 0.90625, 0.9375, 0.921875, 0.921875, 0.90625, 0.90625, 0.953125, 0.96875, 0.953125, 0.90625, 0.921875, 0.9375, 0.90625, 0.921875, 0.875, 0.875, 0.96875, 0.90625, 0.90625]\n",
            "Test_roc:  [0.71280276816609, 0.958477508650519, 0.8166089965397925, 0.8858131487889274, 0.8858131487889274, 0.9619377162629756, 0.9723183391003459, 0.8062283737024222, 0.6955017301038062, 0.8373702422145328, 0.9757785467128027, 0.7370242214532872, 0.8408304498269896, 0.8512110726643598, 0.8304498269896194, 0.9411764705882353, 0.9377162629757786, 0.5743944636678201, 0.9550173010380623, 0.7370242214532872]\n",
            "Train_roc:  [0.7325851393188855, 0.9423374613003095, 0.7976006191950464, 0.8660990712074303, 0.8947368421052632, 0.9527863777089783, 0.9558823529411765, 0.7828947368421053, 0.6830495356037152, 0.789860681114551, 0.9477554179566563, 0.733359133126935, 0.8099845201238389, 0.8510061919504645, 0.7968266253869968, 0.9164086687306502, 0.914860681114551, 0.6021671826625387, 0.9458204334365325, 0.7457430340557276]\n",
            "Best model val:  0.96875\n",
            "Best model test:  0.71280276816609\n",
            "Best model train:  0.96875\n",
            "Average best train: 0.8330882352941176; var: 0.00985235259371795\n",
            "Average best val: 0.9234375; var: 0.0007543945312499997\n",
            "Average best test: 0.8456747404844289; var: 0.011607140719100581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name='gin'\n",
        "predictor = LinkPredictor(gnn_args['hidden_size'], gnn_args['hidden_size'], 1,\n",
        "                          gnn_args['num_layers'], gnn_args['dropout']).to(device)\n",
        "\n",
        "gin_model = GIN(gnn_args['input_size'], gnn_args['hidden_size'], gnn_args['hidden_size'], \n",
        "             gnn_args['num_layers'], gnn_args['dropout']).to(device)\n",
        "\n",
        "train_model(gin_model, data, gnn_args, predictor, 'gin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzNzQjxhgTyL",
        "outputId": "a5dd0aee-0211-462b-8262-ff615f5f16e6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hm\n",
            "Run: 01, Epoch: 100, Loss: 0.9222, Train: 97.33%, Valid: 84.38%, Test: 94.12%\n",
            "---\n",
            "Hm\n",
            "Run: 02, Epoch: 100, Loss: 0.9593, Train: 92.53%, Valid: 93.75%, Test: 90.31%\n",
            "---\n",
            "Hm\n",
            "Run: 03, Epoch: 100, Loss: 0.9103, Train: 90.33%, Valid: 89.06%, Test: 86.85%\n",
            "---\n",
            "Hm\n",
            "Run: 04, Epoch: 100, Loss: 0.8708, Train: 91.18%, Valid: 95.31%, Test: 87.89%\n",
            "---\n",
            "Hm\n",
            "Run: 05, Epoch: 100, Loss: 0.9182, Train: 90.17%, Valid: 87.50%, Test: 86.85%\n",
            "---\n",
            "Hm\n",
            "Run: 06, Epoch: 100, Loss: 0.9103, Train: 92.30%, Valid: 90.62%, Test: 92.39%\n",
            "---\n",
            "Hm\n",
            "Run: 07, Epoch: 100, Loss: 0.8983, Train: 89.40%, Valid: 92.19%, Test: 87.89%\n",
            "---\n",
            "Hm\n",
            "Run: 08, Epoch: 100, Loss: 0.8991, Train: 91.33%, Valid: 87.50%, Test: 91.00%\n",
            "---\n",
            "Hm\n",
            "Run: 09, Epoch: 100, Loss: 0.8601, Train: 94.70%, Valid: 90.62%, Test: 89.97%\n",
            "---\n",
            "Hm\n",
            "Run: 10, Epoch: 100, Loss: 0.9659, Train: 89.59%, Valid: 87.50%, Test: 88.24%\n",
            "---\n",
            "Hm\n",
            "Run: 11, Epoch: 100, Loss: 0.8917, Train: 88.97%, Valid: 98.44%, Test: 83.74%\n",
            "---\n",
            "Hm\n",
            "Run: 12, Epoch: 100, Loss: 1.0852, Train: 89.36%, Valid: 87.50%, Test: 89.62%\n",
            "---\n",
            "Hm\n",
            "Run: 13, Epoch: 100, Loss: 0.9999, Train: 95.82%, Valid: 87.50%, Test: 90.66%\n",
            "---\n",
            "Hm\n",
            "Run: 14, Epoch: 100, Loss: 0.9543, Train: 90.75%, Valid: 87.50%, Test: 91.00%\n",
            "---\n",
            "Hm\n",
            "Run: 15, Epoch: 100, Loss: 0.8643, Train: 91.91%, Valid: 89.06%, Test: 89.27%\n",
            "---\n",
            "Hm\n",
            "Run: 16, Epoch: 100, Loss: 0.8763, Train: 90.13%, Valid: 92.19%, Test: 88.24%\n",
            "---\n",
            "Hm\n",
            "Run: 17, Epoch: 100, Loss: 0.9549, Train: 96.17%, Valid: 90.62%, Test: 92.73%\n",
            "---\n",
            "Hm\n",
            "Run: 18, Epoch: 100, Loss: 1.0645, Train: 92.41%, Valid: 95.31%, Test: 89.97%\n",
            "---\n",
            "Hm\n",
            "Run: 19, Epoch: 100, Loss: 0.8374, Train: 89.94%, Valid: 90.62%, Test: 86.16%\n",
            "---\n",
            "Hm\n",
            "Run: 20, Epoch: 100, Loss: 1.0211, Train: 90.52%, Valid: 90.62%, Test: 82.70%\n",
            "---\n",
            "Val_roc:  [0.890625, 0.9375, 0.953125, 0.96875, 0.953125, 0.953125, 0.953125, 0.953125, 0.921875, 0.953125, 0.984375, 0.890625, 0.90625, 0.921875, 0.9375, 0.953125, 0.953125, 0.953125, 0.9375, 0.921875]\n",
            "Test_roc:  [0.9204152249134948, 0.9031141868512111, 0.8373702422145328, 0.8754325259515571, 0.8581314878892734, 0.8788927335640139, 0.8408304498269896, 0.7993079584775086, 0.8754325259515571, 0.8304498269896194, 0.8373702422145328, 0.8927335640138409, 0.8788927335640138, 0.8615916955017301, 0.8581314878892733, 0.8961937716262975, 0.8788927335640138, 0.8996539792387543, 0.9134948096885813, 0.8754325259515571]\n",
            "Train_roc:  [0.9315015479876161, 0.9253095975232198, 0.8575851393188854, 0.9098297213622291, 0.9024767801857585, 0.871517027863777, 0.8490712074303406, 0.8142414860681115, 0.9214396284829721, 0.8575851393188854, 0.8897058823529411, 0.8804179566563468, 0.9024767801857585, 0.898219814241486, 0.923374613003096, 0.8862229102167183, 0.9094427244582043, 0.9241486068111455, 0.9040247678018576, 0.8440402476780186]\n",
            "Best model val:  0.984375\n",
            "Best model test:  0.8373702422145328\n",
            "Best model train:  0.984375\n",
            "Average best train: 0.8901315789473685; var: 0.0009830065825417668\n",
            "Average best val: 0.93984375; var: 0.0005682373046874999\n",
            "Average best test: 0.8705882352941176; var: 0.0008912728535338426\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "alaCS224W.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}